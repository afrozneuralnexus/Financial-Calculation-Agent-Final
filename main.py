# -*- coding: utf-8 -*-
"""main

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZqWTJPJmUMPcnYt2vuaotU8DpHj6N2JM
"""

import streamlit as st
import pandas as pd
import numpy as np
from decimal import Decimal, ROUND_HALF_UP
import json
import io
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import google.generativeai as genai
import re
from typing import Dict, List, Tuple, Optional
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment
from openpyxl.utils.dataframe import dataframe_to_rows

# Page configuration
st.set_page_config(
    page_title="Financial Calculation Agent",
    page_icon="üí∞",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .kpi-card {
        background-color: #f0f2f6;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 5px solid #1f77b4;
        margin: 1rem 0;
    }
    .metric-value {
        font-size: 2rem;
        font-weight: bold;
        color: #1f77b4;
    }
    .metric-label {
        font-size: 1rem;
        color: #666;
        margin-bottom: 0.5rem;
    }
    .warning-box {
        background-color: #fff3cd;
        border-left: 5px solid #ffc107;
        padding: 1rem;
        margin: 1rem 0;
        border-radius: 5px;
    }
    .error-box {
        background-color: #f8d7da;
        border-left: 5px solid #dc3545;
        padding: 1rem;
        margin: 1rem 0;
        border-radius: 5px;
    }
    .success-box {
        background-color: #d4edda;
        border-left: 5px solid #28a745;
        padding: 1rem;
        margin: 1rem 0;
        border-radius: 5px;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None
if 'field_mapping' not in st.session_state:
    st.session_state.field_mapping = {}
if 'validation_issues' not in st.session_state:
    st.session_state.validation_issues = []
if 'kpis' not in st.session_state:
    st.session_state.kpis = {}
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'raw_data' not in st.session_state:
    st.session_state.raw_data = None

class FinancialCalculationEngine:
    """Core calculation engine for financial KPIs"""

    @staticmethod
    def safe_decimal(value, default=Decimal('0')):
        """Safely convert to Decimal"""
        try:
            if pd.isna(value) or value == '' or value is None:
                return default
            return Decimal(str(value))
        except:
            return default

    @staticmethod
    def calculate_gross_revenue(df: pd.DataFrame) -> Decimal:
        """Gross Revenue = Œ£ (Quantity √ó UnitPrice)"""
        total = Decimal('0')
        for _, row in df.iterrows():
            qty = FinancialCalculationEngine.safe_decimal(row.get('quantity', 0))
            price = FinancialCalculationEngine.safe_decimal(row.get('unit_price', 0))
            total += qty * price
        return total

    @staticmethod
    def calculate_discount_amount(df: pd.DataFrame) -> Decimal:
        """Calculate total discounts"""
        total = Decimal('0')
        for _, row in df.iterrows():
            discount = FinancialCalculationEngine.safe_decimal(row.get('discounts', 0))
            total += discount
        return total

    @staticmethod
    def calculate_tax_amount(df: pd.DataFrame) -> Decimal:
        """Calculate total taxes"""
        total = Decimal('0')
        for _, row in df.iterrows():
            tax = FinancialCalculationEngine.safe_decimal(row.get('taxes', 0))
            total += tax
        return total

    @staticmethod
    def calculate_net_revenue(gross_revenue: Decimal, discount: Decimal, returns: Decimal = Decimal('0')) -> Decimal:
        """Net Revenue = Gross Revenue - Discounts - Returns"""
        return gross_revenue - discount - returns

    @staticmethod
    def calculate_cogs(df: pd.DataFrame) -> Decimal:
        """COGS = Œ£ (Quantity √ó CostPerUnit)"""
        total = Decimal('0')
        for _, row in df.iterrows():
            qty = FinancialCalculationEngine.safe_decimal(row.get('quantity', 0))
            cost = FinancialCalculationEngine.safe_decimal(row.get('cost_per_unit', 0))
            total += qty * cost
        return total

    @staticmethod
    def calculate_gross_profit(net_revenue: Decimal, cogs: Decimal) -> Decimal:
        """Gross Profit = Net Revenue - COGS"""
        return net_revenue - cogs

    @staticmethod
    def calculate_gross_margin_pct(gross_profit: Decimal, net_revenue: Decimal) -> Decimal:
        """Gross Margin % = (Gross Profit / Net Revenue) √ó 100"""
        if net_revenue == 0:
            return Decimal('0')
        return (gross_profit / net_revenue * Decimal('100')).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)

    @staticmethod
    def calculate_all_kpis(df: pd.DataFrame) -> Dict:
        """Calculate all KPIs"""
        gross_revenue = FinancialCalculationEngine.calculate_gross_revenue(df)
        discount_amount = FinancialCalculationEngine.calculate_discount_amount(df)
        tax_amount = FinancialCalculationEngine.calculate_tax_amount(df)
        net_revenue = FinancialCalculationEngine.calculate_net_revenue(gross_revenue, discount_amount)
        cogs = FinancialCalculationEngine.calculate_cogs(df)
        gross_profit = FinancialCalculationEngine.calculate_gross_profit(net_revenue, cogs)
        gross_margin_pct = FinancialCalculationEngine.calculate_gross_margin_pct(gross_profit, net_revenue)

        # Additional metrics
        total_transactions = len(df)
        avg_order_value = net_revenue / Decimal(str(total_transactions)) if total_transactions > 0 else Decimal('0')

        # Average selling price
        total_qty = sum(FinancialCalculationEngine.safe_decimal(row.get('quantity', 0)) for _, row in df.iterrows())
        avg_selling_price = gross_revenue / total_qty if total_qty > 0 else Decimal('0')

        return {
            'gross_revenue': float(gross_revenue),
            'discount_amount': float(discount_amount),
            'tax_amount': float(tax_amount),
            'net_revenue': float(net_revenue),
            'cogs': float(cogs),
            'gross_profit': float(gross_profit),
            'gross_margin_pct': float(gross_margin_pct),
            'total_transactions': total_transactions,
            'avg_order_value': float(avg_order_value),
            'avg_selling_price': float(avg_selling_price)
        }

    @staticmethod
    def calculate_grouped_kpis(df: pd.DataFrame, group_by: str) -> pd.DataFrame:
        """Calculate KPIs grouped by a dimension"""
        if group_by not in df.columns:
            return pd.DataFrame()

        results = []
        for group_value in df[group_by].unique():
            group_df = df[df[group_by] == group_value]
            kpis = FinancialCalculationEngine.calculate_all_kpis(group_df)
            kpis[group_by] = group_value
            results.append(kpis)

        return pd.DataFrame(results)

class DataProcessor:
    """Handle data ingestion, validation, and preprocessing"""

    FIELD_SYNONYMS = {
        'date': ['date', 'order_date', 'invoice_date', 'transaction_date', 'sale_date', 'created_date'],
        'invoice_id': ['invoice_id', 'order_id', 'invoice', 'order', 'transaction_id', 'order_number'],
        'customer_id': ['customer_id', 'customer', 'client_id', 'client', 'customer_name'],
        'product': ['product', 'sku', 'item', 'product_name', 'item_name', 'product_id'],
        'quantity': ['quantity', 'qty', 'units', 'amount', 'units_sold'],
        'unit_price': ['unit_price', 'price', 'selling_price', 'rate', 'unit_selling_price'],
        'discounts': ['discounts', 'discount', 'discount_amount', 'discount_value'],
        'taxes': ['taxes', 'tax', 'tax_amount', 'tax_value'],
        'cost_per_unit': ['cost_per_unit', 'cost', 'unit_cost', 'cogs_per_unit', 'product_cost'],
        'channel': ['channel', 'sales_channel', 'distribution_channel', 'source'],
        'region': ['region', 'country', 'location', 'territory', 'state']
    }

    @staticmethod
    def auto_detect_fields(df: pd.DataFrame) -> Dict[str, str]:
        """Auto-detect field mapping"""
        mapping = {}
        columns_lower = {col: col.lower().strip().replace(' ', '_') for col in df.columns}

        for standard_field, synonyms in DataProcessor.FIELD_SYNONYMS.items():
            for col, col_lower in columns_lower.items():
                if col_lower in synonyms or any(syn in col_lower for syn in synonyms):
                    mapping[standard_field] = col
                    break

        return mapping

    @staticmethod
    def validate_data(df: pd.DataFrame, mapping: Dict[str, str]) -> List[Dict]:
        """Validate data and return issues"""
        issues = []

        # Check required fields
        required_fields = ['date', 'invoice_id', 'product', 'quantity', 'unit_price', 'cost_per_unit']
        for field in required_fields:
            if field not in mapping:
                issues.append({
                    'type': 'error',
                    'field': field,
                    'message': f'Required field "{field}" not found in data'
                })

        if not issues:
            # Check for missing values
            for field, col in mapping.items():
                if field in required_fields:
                    missing_count = df[col].isna().sum()
                    if missing_count > 0:
                        issues.append({
                            'type': 'warning',
                            'field': field,
                            'message': f'{missing_count} missing values in "{field}" ({missing_count/len(df)*100:.1f}%)'
                        })

            # Check for zero or negative prices
            if 'unit_price' in mapping:
                zero_prices = (pd.to_numeric(df[mapping['unit_price']], errors='coerce') <= 0).sum()
                if zero_prices > 0:
                    issues.append({
                        'type': 'warning',
                        'field': 'unit_price',
                        'message': f'{zero_prices} rows with zero or negative unit price'
                    })

            # Check for zero or negative quantities
            if 'quantity' in mapping:
                zero_qty = (pd.to_numeric(df[mapping['quantity']], errors='coerce') <= 0).sum()
                if zero_qty > 0:
                    issues.append({
                        'type': 'warning',
                        'field': 'quantity',
                        'message': f'{zero_qty} rows with zero or negative quantity'
                    })

            # Check for outliers
            if 'unit_price' in mapping:
                prices = pd.to_numeric(df[mapping['unit_price']], errors='coerce')
                median_price = prices.median()
                if median_price > 0:
                    outliers = (prices > median_price * 5).sum()
                    if outliers > 0:
                        issues.append({
                            'type': 'warning',
                            'field': 'unit_price',
                            'message': f'{outliers} potential outliers (>5x median price: ${median_price:.2f})'
                        })

            # Check for duplicate rows
            if 'invoice_id' in mapping:
                duplicates = df[mapping['invoice_id']].duplicated().sum()
                if duplicates > 0:
                    issues.append({
                        'type': 'warning',
                        'field': 'invoice_id',
                        'message': f'{duplicates} duplicate invoice IDs found'
                    })

        return issues

    @staticmethod
    def normalize_data(df: pd.DataFrame, mapping: Dict[str, str]) -> pd.DataFrame:
        """Normalize and clean data"""
        normalized_df = pd.DataFrame()

        for standard_field, source_col in mapping.items():
            if source_col in df.columns:
                if standard_field == 'date':
                    normalized_df[standard_field] = pd.to_datetime(df[source_col], errors='coerce')
                elif standard_field in ['quantity', 'unit_price', 'discounts', 'taxes', 'cost_per_unit']:
                    # Remove currency symbols and commas
                    cleaned = df[source_col].astype(str).str.replace('$', '').str.replace(',', '').str.replace('‚Ç¨', '').str.replace('¬£', '')
                    normalized_df[standard_field] = pd.to_numeric(cleaned, errors='coerce')
                else:
                    normalized_df[standard_field] = df[source_col]

        # Fill missing numeric values with 0
        numeric_fields = ['quantity', 'unit_price', 'discounts', 'taxes', 'cost_per_unit']
        for field in numeric_fields:
            if field in normalized_df.columns:
                normalized_df[field] = normalized_df[field].fillna(0)

        return normalized_df

class GeminiAgent:
    """Gemini AI agent for natural language queries"""

    def __init__(self, api_key: str):
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-pro')

    def analyze_query(self, query: str, kpis: Dict, df: pd.DataFrame) -> str:
        """Analyze user query and provide insights"""

        # Prepare data summary
        date_range = ""
        if 'date' in df.columns:
            min_date = df['date'].min()
            max_date = df['date'].max()
            if pd.notna(min_date) and pd.notna(max_date):
                date_range = f"{min_date.strftime('%Y-%m-%d')} to {max_date.strftime('%Y-%m-%d')}"

        # Get top products if available
        top_products = ""
        if 'product' in df.columns:
            df_temp = df.copy()
            df_temp['revenue'] = df_temp['quantity'] * df_temp['unit_price']
            top_5 = df_temp.groupby('product')['revenue'].sum().nlargest(5)
            top_products = "\n".join([f"  - {prod}: ${rev:,.2f}" for prod, rev in top_5.items()])

        # Get channel breakdown if available
        channel_info = ""
        if 'channel' in df.columns:
            df_temp = df.copy()
            df_temp['revenue'] = df_temp['quantity'] * df_temp['unit_price']
            channel_rev = df_temp.groupby('channel')['revenue'].sum()
            channel_info = "\n".join([f"  - {ch}: ${rev:,.2f}" for ch, rev in channel_rev.items()])

        context = f"""
You are an expert financial analyst assistant. Analyze the user's query and provide detailed, actionable insights based on the available data.

## Current Financial KPIs:
- Gross Revenue: ${kpis.get('gross_revenue', 0):,.2f}
- Net Revenue (after discounts): ${kpis.get('net_revenue', 0):,.2f}
- Total Discounts: ${kpis.get('discount_amount', 0):,.2f}
- Total Taxes: ${kpis.get('tax_amount', 0):,.2f}
- COGS (Cost of Goods Sold): ${kpis.get('cogs', 0):,.2f}
- Gross Profit: ${kpis.get('gross_profit', 0):,.2f}
- Gross Margin %: {kpis.get('gross_margin_pct', 0):.2f}%
- Total Transactions: {kpis.get('total_transactions', 0):,}
- Average Order Value: ${kpis.get('avg_order_value', 0):,.2f}
- Average Selling Price: ${kpis.get('avg_selling_price', 0):,.2f}

## Data Summary:
- Date Range: {date_range if date_range else "Not available"}
- Total Rows: {len(df):,}
- Available Columns: {', '.join(df.columns.tolist())}

{f"## Top 5 Products by Revenue:{chr(10)}{top_products}" if top_products else ""}

{f"## Revenue by Channel:{chr(10)}{channel_info}" if channel_info else ""}

## User Query:
{query}

## Instructions:
1. Provide a clear, concise analysis directly answering the user's question
2. Use specific numbers and percentages from the data
3. Highlight any notable trends, patterns, or anomalies
4. If the query asks for calculations not shown, explain what additional data would be needed
5. Provide actionable recommendations when appropriate
6. Be professional but conversational in tone

Provide your analysis now:
"""

        try:
            response = self.model.generate_content(context)
            return response.text
        except Exception as e:
            return f"Error analyzing query: {str(e)}\n\nPlease check your API key and try again."

def create_excel_export(df: pd.DataFrame, kpis: Dict, mapping: Dict, validation_issues: List) -> io.BytesIO:
    """Create comprehensive Excel export with multiple sheets"""
    output = io.BytesIO()

    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # KPIs Summary Sheet
        kpi_data = [
            ['Metric', 'Value', 'Formula'],
            ['Gross Revenue', f"${kpis.get('gross_revenue', 0):,.2f}", 'Œ£(Quantity √ó Unit Price)'],
            ['Discount Amount', f"${kpis.get('discount_amount', 0):,.2f}", 'Œ£(Discounts)'],
            ['Tax Amount', f"${kpis.get('tax_amount', 0):,.2f}", 'Œ£(Taxes)'],
            ['Net Revenue', f"${kpis.get('net_revenue', 0):,.2f}", 'Gross Revenue - Discounts'],
            ['COGS', f"${kpis.get('cogs', 0):,.2f}", 'Œ£(Quantity √ó Cost Per Unit)'],
            ['Gross Profit', f"${kpis.get('gross_profit', 0):,.2f}", 'Net Revenue - COGS'],
            ['Gross Margin %', f"{kpis.get('gross_margin_pct', 0):.2f}%", '(Gross Profit / Net Revenue) √ó 100'],
            ['Total Transactions', f"{kpis.get('total_transactions', 0):,}", 'COUNT(Rows)'],
            ['Average Order Value', f"${kpis.get('avg_order_value', 0):,.2f}", 'Net Revenue / Total Transactions'],
            ['Average Selling Price', f"${kpis.get('avg_selling_price', 0):,.2f}", 'Gross Revenue / Total Quantity'],
        ]

        kpi_df = pd.DataFrame(kpi_data[1:], columns=kpi_data[0])
        kpi_df.to_excel(writer, sheet_name='KPI Summary', index=False)

        # Raw processed data
        df.to_excel(writer, sheet_name='Processed Data', index=False)

        # Field mapping
        mapping_data = [['Standard Field', 'Source Column']]
        for k, v in mapping.items():
            mapping_data.append([k, v])

        mapping_df = pd.DataFrame(mapping_data[1:], columns=mapping_data[0])
        mapping_df.to_excel(writer, sheet_name='Field Mapping', index=False)

        # Validation issues
        if validation_issues:
            issues_data = [['Type', 'Field', 'Message']]
            for issue in validation_issues:
                issues_data.append([issue['type'], issue['field'], issue['message']])

            issues_df = pd.DataFrame(issues_data[1:], columns=issues_data[0])
            issues_df.to_excel(writer, sheet_name='Validation Issues', index=False)

        # Product analysis if available
        if 'product' in df.columns:
            product_kpis = FinancialCalculationEngine.calculate_grouped_kpis(df, 'product')
            if not product_kpis.empty:
                product_kpis = product_kpis.sort_values('gross_revenue', ascending=False)
                product_kpis.to_excel(writer, sheet_name='Product Analysis', index=False)

        # Channel analysis if available
        if 'channel' in df.columns:
            channel_kpis = FinancialCalculationEngine.calculate_grouped_kpis(df, 'channel')
            if not channel_kpis.empty:
                channel_kpis = channel_kpis.sort_values('gross_revenue', ascending=False)
                channel_kpis.to_excel(writer, sheet_name='Channel Analysis', index=False)

    output.seek(0)
    return output

def main():
    st.markdown('<h1 class="main-header">üí∞ Financial Calculation Agent</h1>', unsafe_allow_html=True)

    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration")

        # API Key input
        api_key = st.text_input(
            "Google Gemini API Key",
            type="password",
            help="Enter your Google Gemini API key. Get one at https://makersuite.google.com/app/apikey"
        )

        if api_key:
            st.success("‚úÖ API Key configured")
        else:
            st.info("‚ÑπÔ∏è Enter API key to enable AI chat")

        st.divider()

        st.header("üìä Features")
        st.markdown("""
        - ‚úÖ **Multi-format support**: CSV, XLSX, JSON
        - ‚úÖ **Auto field detection**
        - ‚úÖ **Comprehensive KPIs**
        - ‚úÖ **Data validation**
        - ‚úÖ **AI-powered insights**
        - ‚úÖ **Advanced visualizations**
        - ‚úÖ **Multi-sheet Excel export**
        - ‚úÖ **Product & Channel analysis**
        """)

        st.divider()

        st.header("üìñ Quick Guide")
        st.markdown("""
        **Step 1:** Upload your sales data file

        **Step 2:** Review and confirm field mapping

        **Step 3:** Check validation results

        **Step 4:** View KPIs and interactive charts

        **Step 5:** Ask questions using AI chat

        **Step 6:** Export comprehensive reports
        """)

        st.divider()

        st.header("üìù Sample Data Format")
        with st.expander("View required columns"):
            st.code("""
Required columns:
‚Ä¢ date (YYYY-MM-DD)
‚Ä¢ invoice_id
‚Ä¢ product/sku
‚Ä¢ quantity
‚Ä¢ unit_price
‚Ä¢ cost_per_unit

Optional columns:
‚Ä¢ customer_id
‚Ä¢ discounts
‚Ä¢ taxes
‚Ä¢ channel
‚Ä¢ region
            """)

    # Main content
    tab1, tab2, tab3, tab4 = st.tabs(["üì§ Upload & Map", "üìä Dashboard", "üí¨ AI Chat", "üì• Export"])

    with tab1:
        st.header("Upload Sales Data")

        col1, col2 = st.columns([2, 1])
        with col1:
            uploaded_file = st.file_uploader(
                "Choose a file (CSV, XLSX, or JSON)",
                type=['csv', 'xlsx', 'json'],
                help="Upload your sales report file with transaction data"
            )

        with col2:
            st.info("""
            **Supported formats:**
            - CSV files
            - Excel files (.xlsx)
            - JSON files
            """)

        if uploaded_file:
            try:
                # Read file
                with st.spinner("üìÇ Loading file..."):
                    if uploaded_file.name.endswith('.csv'):
                        df = pd.read_csv(uploaded_file)
                    elif uploaded_file.name.endswith('.xlsx'):
                        df = pd.read_excel(uploaded_file)
                    elif uploaded_file.name.endswith('.json'):
                        df = pd.read_json(uploaded_file)

                    st.session_state.raw_data = df.copy()

                st.success(f"‚úÖ File loaded successfully: **{len(df):,}** rows, **{len(df.columns)}** columns")

                # Show file info
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Total Rows", f"{len(df):,}")
                with col2:
                    st.metric("Total Columns", len(df.columns))
                with col3:
                    file_size = uploaded_file.size / 1024  # KB
                    st.metric("File Size", f"{file_size:.1f} KB")

                # Show preview
                st.subheader("üìã Data Preview")
                with st.expander("View first 50 rows", expanded=True):
                    st.dataframe(df.head(50), use_container_width=True, height=400)

                st.divider()

                # Auto-detect fields
                st.subheader("üîç Field Mapping")
                st.info("üëá Review auto-detected fields below. You can manually adjust any mapping if needed.")

                auto_mapping = DataProcessor.auto_detect_fields(df)

                col1, col2 = st.columns(2)
                mapping = {}

                required_fields = ['date', 'invoice_id', 'product', 'quantity', 'unit_price', 'cost_per_unit']
                optional_fields = ['customer_id', 'discounts', 'taxes', 'channel', 'region']

                with col1:
                    st.markdown("**üìå Required Fields**")
                    for field in required_fields:
                        default_value = auto_mapping.get(field, '')
                        selected = st.selectbox(
                            f"{field.replace('_', ' ').title()} *",
                            options=[''] + list(df.columns),
                            index=list([''] + list(df.columns)).index(default_value) if default_value in df.columns else 0,
                            key=f"map_{field}",
                            help=f"Map source column to {field}"
                        )
                        if selected:
                            mapping[field] = selected

                with col2:
                    st.markdown("**‚ûï Optional Fields**")
                    for field in optional_fields:
                        default_value = auto_mapping.get(field, '')
                        selected = st.selectbox(
                            field.replace('_', ' ').title(),
                            options=[''] + list(df.columns),
                            index=list([''] + list(df.columns)).index(default_value) if default_value in df.columns else 0,
                            key=f"map_{field}",
                            help=f"Map source column to {field} (optional)"
                        )
                        if selected:
                            mapping[field] = selected

                st.divider()

                # Validate button
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    validate_button = st.button(
                        "‚úÖ Validate & Process Data",
                        type="primary",
                        use_container_width=True,
                        help="Validate field mappings and process the data"
                    )

                if validate_button:
                    with st.spinner("üîÑ Validating data..."):
                        issues = DataProcessor.validate_data(df, mapping)
                        st.session_state.validation_issues = issues
                        st.session_state.field_mapping = mapping

                    st.subheader("üìä Validation Results")

                    if issues:
                        error_count = sum(1 for i in issues if i['type'] == 'error')
                        warning_count = sum(1 for i in issues if i['type'] == 'warning')

                        col1, col2 = st.columns(2)
                        with col1:
                            if error_count > 0:
                                st.error(f"‚ùå {error_count} Error(s) Found")
                        with col2:
                            if warning_count > 0:
                                st.warning(f"‚ö†Ô∏è {warning_count} Warning(s) Found")

                        for issue in issues:
                            if issue['type'] == 'error':
                                st.markdown(
                                    f'<div class="error-box">‚ùå <strong>{issue["field"]}</strong>: {issue["message"]}</div>',
                                    unsafe_allow_html=True
                                )
                            else:
                                st.markdown(
                                    f'<div class="warning-box">‚ö†Ô∏è <strong>{issue["field"]}</strong>: {issue["message"]}</div>',
                                    unsafe_allow_html=True
                                )

                        # Check if any errors
                        has_errors = any(issue['type'] == 'error' for issue in issues)

                        if not has_errors:
                            st.divider()
                            col1, col2, col3 = st.columns([1, 2, 1])
                            with col2:
                                if st.button("Continue with Warnings", type="primary", use_container_width=True):
                                    with st.spinner("üîÑ Processing data..."):
                                        normalized_df = DataProcessor.normalize_data(df, mapping)
                                        st.session_state.processed_data = normalized_df
                                        kpis = FinancialCalculationEngine.calculate_all_kpis(normalized_df)
                                        st.session_state.kpis = kpis
                                    st.success("‚úÖ Data processed successfully!")
                                    st.balloons()
                                    st.rerun()
                        else:
                            st.error("‚ùå Please fix the errors above before proceeding.")
                    else:
                        st.markdown('<div class="success-box">‚úÖ All validations passed! No issues found.</div>', unsafe_allow_html=True)

                        with st.spinner("üîÑ Processing data..."):
                            normalized_df = DataProcessor.normalize_data(df, mapping)
                            st.session_state.processed_data = normalized_df
                            kpis = FinancialCalculationEngine.calculate_all_kpis(normalized_df)
                            st.session_state.kpis = kpis

                        st.success("‚úÖ Data processed successfully! Navigate to the Dashboard tab to view results.")
                        st.balloons()
                        st.rerun()

            except Exception as e:
                st.error(f"‚ùå Error loading file: {str(e)}")
                st.exception(e)
        else:
            st.info("üëÜ Please upload a sales data file to begin")

    with tab2:
        if st.session_state.processed_data is not None and st.session_state.kpis:
            df = st.session_state.processed_data
            kpis = st.session_state.kpis

            st.header("üìä Financial Dashboard")

            # KPI Cards
            st.subheader("üí∞ Key Performance Indicators")
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric(
                    "Gross Revenue",
                    f"${kpis['gross_revenue']:,.2f}",
                    help="Total revenue before discounts"
                )
                st.metric(
                    "Net Revenue",
                    f"${kpis['net_revenue']:,.2f}",
                    delta=f"-${kpis['discount_amount']:,.2f}" if kpis['discount_amount'] > 0 else None,
                    help="Revenue after discounts"
                )

            with col2:
                st.metric(
                    "COGS",
                    f"${kpis['cogs']:,.2f}",
                    help="Cost of Goods Sold"
                )
                st.metric(
                    "Gross Profit",
                    f"${kpis['gross_profit']:,.2f}",
                    help="Net Revenue - COGS"
                )

            with col3:
                st.metric(
                    "Gross Margin %",
                    f"{kpis['gross_margin_pct']:.2f}%",
                    help="(Gross Profit / Net Revenue) √ó 100"
                )
                st.metric(
                    "Total Discounts",
                    f"${kpis['discount_amount']:,.2f}",
                    help="Total discount amount"
                )

            with col4:
                st.metric(
                    "Transactions",
                    f"{kpis['total_transactions']:,}",
                    help="Total number of transactions"
                )
                st.metric(
                    "Avg Order Value",
                    f"${kpis['avg_order_value']:,.2f}",
                    help="Average revenue per transaction"
                )

            st.divider()

            # Charts Section
            st.subheader("üìà Visual Analytics")

            # Row 1: Revenue breakdown and Waterfall
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**Revenue Breakdown**")
                fig = go.Figure(data=[go.Pie(
                    labels=['Gross Profit', 'COGS', 'Discounts'],
                    values=[
                        max(0, kpis['gross_profit']),
                        max(0, kpis['cogs']),
                        max(0, kpis['discount_amount'])
                    ],
                    hole=0.4,
                    marker=dict(colors=['#2ecc71', '#e74c3c', '#f39c12'])
                )])
                fig.update_layout(height=350, showlegend=True)
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                st.markdown("**Revenue Waterfall**")
                fig = go.Figure(go.Waterfall(
                    name="Revenue Flow",
                    orientation="v",
                    x=['Gross Revenue', 'Discounts', 'Net Revenue', 'COGS', 'Gross Profit'],
                    y=[
                        kpis['gross_revenue'],
                        -kpis['discount_amount'],
                        0,
                        -kpis['cogs'],
                        0
                    ],
                    text=[
                        f"${kpis['gross_revenue']:,.0f}",
                        f"-${kpis['discount_amount']:,.0f}",
                        f"${kpis['net_revenue']:,.0f}",
                        f"-${kpis['cogs']:,.0f}",
                        f"${kpis['gross_profit']:,.0f}"
                    ],
                    textposition="outside",
                    connector={"line": {"color": "rgb(63, 63, 63)"}},
                    decreasing={"marker": {"color": "#e74c3c"}},
                    increasing={"marker": {"color": "#2ecc71"}},
                    totals={"marker": {"color": "#3498db"}}
                ))
                fig.update_layout(height=350, showlegend=False)
                st.plotly_chart(fig, use_container_width=True)

            st.divider()

            # Time series if date available
            if 'date' in df.columns and df['date'].notna().any():
                st.subheader("üìÖ Time-Based Analysis")

                df_time = df.copy()
                df_time['revenue'] = df_time['quantity'] * df_time['unit_price']
                df_time['profit'] = (df_time['unit_price'] - df_time['cost_per_unit']) * df_time['quantity']

                # Group by date
                daily_data = df_time.groupby(df_time['date'].dt.date).agg({
                    'revenue': 'sum',
                    'profit': 'sum',
                    'quantity': 'sum'
                }).reset_index()

                # Create tabs for different views
                time_tab1, time_tab2 = st.tabs(["üìä Revenue Trend", "üíπ Profit Trend"])

                with time_tab1:
                    fig = px.line(
                        daily_data,
                        x='date',
                        y='revenue',
                        title='Daily Revenue Trend',
                        markers=True
                    )
                    fig.update_traces(line_color='#3498db', line_width=2)
                    fig.update_layout(
                        height=400,
                        xaxis_title="Date",
                        yaxis_title="Revenue ($)",
                        hovermode='x unified'
                    )
                    st.plotly_chart(fig, use_container_width=True)

                with time_tab2:
                    fig = px.line(
                        daily_data,
                        x='date',
                        y='profit',
                        title='Daily Profit Trend',
                        markers=True
                    )
                    fig.update_traces(line_color='#2ecc71', line_width=2)
                    fig.update_layout(
                        height=400,
                        xaxis_title="Date",
                        yaxis_title="Profit ($)",
                        hovermode='x unified'
                    )
                    st.plotly_chart(fig, use_container_width=True)

                st.divider()

            # Product analysis if available
            if 'product' in df.columns:
                st.subheader("üèÜ Product Performance")

                df_product = df.copy()
                df_product['revenue'] = df_product['quantity'] * df_product['unit_price']
                df_product['profit'] = (df_product['unit_price'] - df_product['cost_per_unit']) * df_product['quantity']

                product_summary = df_product.groupby('product').agg({
                    'revenue': 'sum',
                    'profit': 'sum',
                    'quantity': 'sum'
                }).reset_index()

                product_summary['margin_pct'] = (product_summary['profit'] / product_summary['revenue'] * 100).round(2)
                product_summary = product_summary.sort_values('revenue', ascending=False)

                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("**Top 10 Products by Revenue**")
                    top_10_revenue = product_summary.head(10)
                    fig = px.bar(
                        top_10_revenue,
                        x='product',
                        y='revenue',
                        text='revenue',
                        color='revenue',
                        color_continuous_scale='Blues'
                    )
                    fig.update_traces(texttemplate='$%{text:,.0f}', textposition='outside')
                    fig.update_layout(
                        height=400,
                        xaxis_title="Product",
                        yaxis_title="Revenue ($)",
                        showlegend=False
                    )
                    fig.update_xaxes(tickangle=-45)
                    st.plotly_chart(fig, use_container_width=True)

                with col2:
                    st.markdown("**Top 10 Products by Profit Margin**")
                    top_10_margin = product_summary.nlargest(10, 'margin_pct')
                    fig = px.bar(
                        top_10_margin,
                        x='product',
                        y='margin_pct',
                        text='margin_pct',
                        color='margin_pct',
                        color_continuous_scale='Greens'
                    )
                    fig.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
                    fig.update_layout(
                        height=400,
                        xaxis_title="Product",
                        yaxis_title="Profit Margin (%)",
                        showlegend=False
                    )
                    fig.update_xaxes(tickangle=-45)
                    st.plotly_chart(fig, use_container_width=True)

                # Product table
                st.markdown("**üìã Detailed Product Analysis**")
                product_display = product_summary.copy()
                product_display['revenue'] = product_display['revenue'].apply(lambda x: f"${x:,.2f}")
                product_display['profit'] = product_display['profit'].apply(lambda x: f"${x:,.2f}")
                product_display['quantity'] = product_display['quantity'].apply(lambda x: f"{x:,.0f}")
                product_display['margin_pct'] = product_display['margin_pct'].apply(lambda x: f"{x:.2f}%")

                st.dataframe(
                    product_display,
                    column_config={
                        "product": "Product",
                        "revenue": "Revenue",
                        "profit": "Profit",
                        "quantity": "Units Sold",
                        "margin_pct": "Margin %"
                    },
                    hide_index=True,
                    use_container_width=True
                )

                st.divider()

            # Channel analysis if available
            if 'channel' in df.columns:
                st.subheader("üåê Channel Performance")

                df_channel = df.copy()
                df_channel['revenue'] = df_channel['quantity'] * df_channel['unit_price']
                df_channel['profit'] = (df_channel['unit_price'] - df_channel['cost_per_unit']) * df_channel['quantity']

                channel_summary = df_channel.groupby('channel').agg({
                    'revenue': 'sum',
                    'profit': 'sum',
                    'quantity': 'sum',
                    'invoice_id': 'count'
                }).reset_index()

                channel_summary.rename(columns={'invoice_id': 'transactions'}, inplace=True)
                channel_summary['margin_pct'] = (channel_summary['profit'] / channel_summary['revenue'] * 100).round(2)
                channel_summary = channel_summary.sort_values('revenue', ascending=False)

                col1, col2 = st.columns(2)

                with col1:
                    fig = px.bar(
                        channel_summary,
                        x='channel',
                        y='revenue',
                        text='revenue',
                        title='Revenue by Channel',
                        color='revenue',
                        color_continuous_scale='Viridis'
                    )
                    fig.update_traces(texttemplate='$%{text:,.0f}', textposition='outside')
                    fig.update_layout(height=400, showlegend=False)
                    st.plotly_chart(fig, use_container_width=True)

                with col2:
                    fig = px.pie(
                        channel_summary,
                        values='transactions',
                        names='channel',
                        title='Transaction Distribution by Channel',
                        hole=0.4
                    )
                    fig.update_layout(height=400)
                    st.plotly_chart(fig, use_container_width=True)

                # Channel table
                st.markdown("**üìã Detailed Channel Analysis**")
                channel_display = channel_summary.copy()
                channel_display['revenue'] = channel_display['revenue'].apply(lambda x: f"${x:,.2f}")
                channel_display['profit'] = channel_display['profit'].apply(lambda x: f"${x:,.2f}")
                channel_display['quantity'] = channel_display['quantity'].apply(lambda x: f"{x:,.0f}")
                channel_display['transactions'] = channel_display['transactions'].apply(lambda x: f"{x:,}")
                channel_display['margin_pct'] = channel_display['margin_pct'].apply(lambda x: f"{x:.2f}%")

                st.dataframe(
                    channel_display,
                    column_config={
                        "channel": "Channel",
                        "revenue": "Revenue",
                        "profit": "Profit",
                        "quantity": "Units Sold",
                        "transactions": "Transactions",
                        "margin_pct": "Margin %"
                    },
                    hide_index=True,
                    use_container_width=True
                )

        else:
            st.info("üëÜ Please upload and process data in the 'Upload & Map' tab first")

            # Show sample visualization
            st.markdown("### üìä Sample Dashboard Preview")
            st.image("https://via.placeholder.com/800x400/3498db/ffffff?text=Upload+Data+to+View+Dashboard", use_container_width=True)

    with tab3:
        st.header("üí¨ AI Financial Assistant")

        if not api_key:
            st.warning("‚ö†Ô∏è Please enter your Google Gemini API key in the sidebar to use the AI chat feature")
            st.info("""
            **How to get an API key:**
            1. Visit https://makersuite.google.com/app/apikey
            2. Sign in with your Google account
            3. Create a new API key
            4. Copy and paste it in the sidebar
            """)
        elif st.session_state.processed_data is None:
            st.info("üëÜ Please upload and process data in the 'Upload & Map' tab first")
        else:
            # Initialize agent
            agent = GeminiAgent(api_key)

            st.markdown("""
            Ask me anything about your financial data! Here are some example questions:
            - What are the key insights from this data?
            - Which products are most profitable?
            - How can we improve our gross margin?
            - What trends do you see in the revenue?
            - Compare performance across channels
            """)

            st.divider()

            # Display chat history
            for message in st.session_state.chat_history:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

            # Chat input
            if query := st.chat_input("Ask me anything about your financial data..."):
                # Add user message
                st.session_state.chat_history.append({"role": "user", "content": query})
                with st.chat_message("user"):
                    st.markdown(query)

                # Get AI response
                with st.chat_message("assistant"):
                    with st.spinner("ü§î Analyzing your data..."):
                        response = agent.analyze_query(
                            query,
                            st.session_state.kpis,
                            st.session_state.processed_data
                        )
                        st.markdown(response)
                        st.session_state.chat_history.append({"role": "assistant", "content": response})

            # Sidebar buttons
            col1, col2 = st.columns(2)
            with col1:
                if st.button("üóëÔ∏è Clear Chat History", use_container_width=True):
                    st.session_state.chat_history = []
                    st.rerun()

            with col2:
                if st.button("üí° Suggest Questions", use_container_width=True):
                    suggestions = [
                        "What are the top 5 insights from this financial data?",
                        "Which products should we focus on to improve profitability?",
                        "Are there any concerning trends in the data?",
                        "How does our performance vary across different channels?",
                        "What recommendations do you have to increase revenue?"
                    ]
                    st.info("**Suggested Questions:**\n\n" + "\n".join([f"‚Ä¢ {s}" for s in suggestions]))

    with tab4:
        st.header("üì• Export Results")

        if st.session_state.processed_data is not None and st.session_state.kpis:
            st.success("‚úÖ Data ready for export")

            # Export options
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("### üìä Excel Export")
                st.markdown("""
                **Comprehensive Excel workbook includes:**
                - üìà KPI Summary with formulas
                - üìã Processed data
                - üîó Field mapping reference
                - ‚ö†Ô∏è Validation issues log
                - üì¶ Product analysis
                - üåê Channel analysis
                """)

                try:
                    excel_data = create_excel_export(
                        st.session_state.processed_data,
                        st.session_state.kpis,
                        st.session_state.field_mapping,
                        st.session_state.validation_issues
                    )

                    st.download_button(
                        label="üì• Download Excel Report",
                        data=excel_data,
                        file_name=f"financial_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True,
                        type="primary"
                    )
                except Exception as e:
                    st.error(f"Error creating Excel file: {str(e)}")

            with col2:
                st.markdown("### üìÑ JSON Export")
                st.markdown("""
                **JSON export includes:**
                - üí∞ All calculated KPIs
                - üìä Metadata and statistics
                - üìÖ Date range information
                - üî¢ Transaction counts
                - üìê Calculation formulas
                """)

                json_data = {
                    'export_timestamp': datetime.now().isoformat(),
                    'kpis': st.session_state.kpis,
                    'formulas': {
                        'gross_revenue': 'Œ£(Quantity √ó Unit Price)',
                        'net_revenue': 'Gross Revenue - Discounts',
                        'cogs': 'Œ£(Quantity √ó Cost Per Unit)',
                        'gross_profit': 'Net Revenue - COGS',
                        'gross_margin_pct': '(Gross Profit / Net Revenue) √ó 100'
                    },
                    'metadata': {
                        'total_rows': len(st.session_state.processed_data),
                        'total_columns': len(st.session_state.processed_data.columns),
                        'date_range': {
                            'start': str(st.session_state.processed_data['date'].min()) if 'date' in st.session_state.processed_data.columns and st.session_state.processed_data['date'].notna().any() else None,
                            'end': str(st.session_state.processed_data['date'].max()) if 'date' in st.session_state.processed_data.columns and st.session_state.processed_data['date'].notna().any() else None
                        },
                        'field_mapping': st.session_state.field_mapping
                    }
                }

                st.download_button(
                    label="üì• Download JSON Data",
                    data=json.dumps(json_data, indent=2),
                    file_name=f"financial_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    use_container_width=True,
                    type="primary"
                )

            st.divider()

            # CSV Export
            st.markdown("### üìë CSV Export")
            col1, col2 = st.columns(2)

            with col1:
                csv_processed = st.session_state.processed_data.to_csv(index=False)
                st.download_button(
                    label="üì• Download Processed Data (CSV)",
                    data=csv_processed,
                    file_name=f"processed_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )

            with col2:
                if st.session_state.raw_data is not None:
                    csv_raw = st.session_state.raw_data.to_csv(index=False)
                    st.download_button(
                        label="üì• Download Raw Data (CSV)",
                        data=csv_raw,
                        file_name=f"raw_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )

            st.divider()

            # Audit Trail
            st.markdown("### üìã Audit Trail & Calculation Details")
            with st.expander("View Detailed Calculation Information", expanded=False):
                st.markdown("#### Formulas Used:")
                st.code("""
1. Gross Revenue = Œ£(Quantity √ó Unit Price)
2. Discount Amount = Œ£(Discounts)
3. Tax Amount = Œ£(Taxes)
4. Net Revenue = Gross Revenue - Discount Amount
5. COGS = Œ£(Quantity √ó Cost Per Unit)
6. Gross Profit = Net Revenue - COGS
7. Gross Margin % = (Gross Profit / Net Revenue) √ó 100
8. Average Order Value = Net Revenue / Total Transactions
9. Average Selling Price = Gross Revenue / Total Quantity
                """)

                st.markdown("#### Processing Summary:")
                summary_data = {
                    "Metric": [
                        "File Processed",
                        "Total Rows",
                        "Valid Rows",
                        "Processing Date",
                        "Calculation Method",
                        "Decimal Precision"
                    ],
                    "Value": [
                        "‚úÖ Success",
                        f"{len(st.session_state.processed_data):,}",
                        f"{len(st.session_state.processed_data):,}",
                        datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "Decimal arithmetic (high precision)",
                        "2 decimal places"
                    ]
                }
                st.table(pd.DataFrame(summary_data))

                if st.session_state.validation_issues:
                    st.markdown("#### Validation Issues:")
                    issues_df = pd.DataFrame(st.session_state.validation_issues)
                    st.dataframe(issues_df, use_container_width=True)

        else:
            st.info("üëÜ Please upload and process data in the 'Upload & Map' tab first")

            st.markdown("### üì¶ Available Export Formats")
            st.markdown("""
            Once you process your data, you'll be able to export in multiple formats:

            - **Excel (.xlsx)** - Multi-sheet workbook with KPIs, analysis, and audit trail
            - **JSON** - Structured data with metadata and formulas
            - **CSV** - Both processed and raw data exports
            """)

if __name__ == "__main__":
    main()